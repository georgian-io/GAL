{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create evaluation dataset\n",
    "\n",
    "Next, we're going to create an evaluation dataset for our app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the earlier notebook\n",
    "\n",
    "First, we run the code from the previous notebook. The code below does this for us, we don't need to go back to that notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 01-llm-app-setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Take the document chunks created earlier\n",
    "\n",
    "These are the chunks of documents in our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       " Document(page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       " Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       " Document(page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       " Document(page_content='Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup a chain to ask the LLM to create question and answer pairs. \n",
    "\n",
    "We'll use GPT-4 here to ensure good Q&A generation. These are generated based on a given chunk of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class QAExample(BaseModel):\n",
    "    question: str = Field(description=\"question relevant to the given input\")\n",
    "    answer: str = Field(description=\"answer to the question\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"question\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=QAExample)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Given the following text, generate a set of question and answer about an information contained in the text.\\n{format_instructions}\\nText:\\n```\\n{text}\\n```\\n\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Like before, you can replace this with a different LLM\n",
    "gpt4_llm = ChatOpenAI(model_name=\"gpt-4-turbo-preview\", temperature=0)\n",
    "\n",
    "gen_qa_chain = prompt | gpt4_llm | parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n"
     ]
    }
   ],
   "source": [
    "print(splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QAExample(question='What is the core controller of the autonomous agents discussed in the text?', answer='LLM (large language model)')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_qa_chain.invoke({\"text\": splits[0].page_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate the dataset\n",
    "\n",
    "The output above looks good, so let's run the chain over our entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_qa = []\n",
    "\n",
    "for split in splits:\n",
    "    gen_qa.append(gen_qa_chain.invoke({\"text\": split.page_content}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QAExample(question='What is the core controller of the autonomous agents discussed in the text?', answer='LLM (large language model)'),\n",
       " QAExample(question='What is considered as utilizing the short-term memory of the model?', answer='In-context learning, as seen in Prompt Engineering, utilizes the short-term memory of the model.'),\n",
       " QAExample(question='What is the purpose of the Chain of Thought (CoT) prompting technique according to Wei et al. 2022?', answer=\"The purpose of the Chain of Thought (CoT) prompting technique is to enhance model performance on complex tasks by instructing the model to 'think step by step', which allows it to utilize more test-time computation to decompose hard tasks into smaller and simpler steps, thereby transforming big tasks into multiple manageable tasks and shedding light into an interpretation of the model’s thinking process.\"),\n",
       " QAExample(question='What does the Tree of Thoughts (Yao et al. 2023) extend and what new approach does it introduce?', answer='Tree of Thoughts extends CoT by exploring multiple reasoning possibilities at each step, decomposing the problem into multiple thought steps, and generating multiple thoughts per step to create a tree structure.'),\n",
       " QAExample(question='What is the distinct approach called that involves relying on an external classical planner for long-horizon planning?', answer='LLM+P (Liu et al. 2023)')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_qa[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate negative samples\n",
    "\n",
    "Let's also make some questions where the answer is not in any parts of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Given the following text, generate a question about information not contained in the text, with the answer confirming that the information is not included.\\n{format_instructions}\\nText:\\n```\\n{text}\\n```\\n\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Increase the temperature to get more diverse questions and answers.\n",
    "gpt4_llm = ChatOpenAI(model_name=\"gpt-4-turbo-preview\", temperature=0.7)\n",
    "\n",
    "gen_qa_chain = prompt | gpt4_llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to make sure the questions generated are varied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question='Does the text mention any specific challenges related to the energy consumption of LLM-powered autonomous agents?' answer='No, the text does not mention specific challenges related to the energy consumption of LLM-powered autonomous agents.'\n",
      "question='Does the text provide any specific examples of real-world applications where LLM-powered autonomous agents have been successfully deployed?' answer='No, the text does not provide specific examples of real-world applications where LLM-powered autonomous agents have been successfully deployed.'\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(gen_qa_chain.invoke({\"text\": docs[0].page_content}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, let's run it a few more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_qa_no_answer = []\n",
    "\n",
    "for i in range(10):\n",
    "    gen_qa_no_answer.append(gen_qa_chain.invoke({\"text\": docs[0].page_content}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QAExample(question='What specific challenges do LLMs face when interpreting and generating natural language instructions for complex, multi-step tasks?', answer='This information is not included in the text.'),\n",
       " QAExample(question='Does the text provide any specific examples of how LLM-powered autonomous agents have been integrated into commercial products or services?', answer='No, the text does not provide specific examples of integration into commercial products or services.'),\n",
       " QAExample(question='Does the text provide any specific examples of real-world applications outside of experimental or conceptual frameworks?', answer='No, the text does not provide specific examples of real-world applications outside of experimental or conceptual frameworks.'),\n",
       " QAExample(question='Does the text provide any specific examples of LLM-powered autonomous agents being used in educational settings, such as tutoring or personalized learning?', answer='No, the text does not provide examples of LLM-powered autonomous agents being used in educational settings.'),\n",
       " QAExample(question='Does the text provide specific examples of how the MRKL system was tested in real-world applications?', answer='No, the text does not provide specific examples of real-world applications where the MRKL system was tested.'),\n",
       " QAExample(question='Does the text provide any specific examples of how LLM-powered autonomous agents have been integrated into consumer products or services?', answer='No, the text does not provide specific examples of LLM-powered autonomous agents integrated into consumer products or services.'),\n",
       " QAExample(question='What are the specific programming languages used in the development of the agent systems mentioned in the text?', answer='The text does not specify which programming languages were used in the development of the agent systems.'),\n",
       " QAExample(question='Does the text provide any specific examples of LLM-powered autonomous agents being implemented in educational settings to enhance learning?', answer='No, the text does not provide specific examples of LLM-powered autonomous agents being implemented in educational settings to enhance learning.'),\n",
       " QAExample(question='Does the text provide any specific examples of how LLM-powered autonomous agents have been integrated into consumer electronics?', answer='No, the text does not provide specific examples of LLM-powered autonomous agents integrated into consumer electronics.'),\n",
       " QAExample(question='What are the specific ethical guidelines mentioned for the development and deployment of LLM-powered autonomous agents?', answer='The text does not include specific ethical guidelines for the development and deployment of LLM-powered autonomous agents.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_qa_no_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the datasets\n",
    "\n",
    "Let's put this in a dataframe so we don't need to rerun all the code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>ground_truth_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the core controller of the autonomous ...</td>\n",
       "      <td>LLM (large language model)</td>\n",
       "      <td>LLM Powered Autonomous Agents\\n    \\nDate: Jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is considered as utilizing the short-term...</td>\n",
       "      <td>In-context learning, as seen in Prompt Enginee...</td>\n",
       "      <td>Memory\\n\\nShort-term memory: I would consider ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of the Chain of Thought (C...</td>\n",
       "      <td>The purpose of the Chain of Thought (CoT) prom...</td>\n",
       "      <td>Fig. 1. Overview of a LLM-powered autonomous a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the Tree of Thoughts (Yao et al. 202...</td>\n",
       "      <td>Tree of Thoughts extends CoT by exploring mult...</td>\n",
       "      <td>Tree of Thoughts (Yao et al. 2023) extends CoT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the distinct approach called that invo...</td>\n",
       "      <td>LLM+P (Liu et al. 2023)</td>\n",
       "      <td>Another quite distinct approach, LLM+P (Liu et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Does the text provide any specific examples of...</td>\n",
       "      <td>No, the text does not provide specific example...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>What are the specific programming languages us...</td>\n",
       "      <td>The text does not specify which programming la...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Does the text provide any specific examples of...</td>\n",
       "      <td>No, the text does not provide specific example...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Does the text provide any specific examples of...</td>\n",
       "      <td>No, the text does not provide specific example...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>What are the specific ethical guidelines menti...</td>\n",
       "      <td>The text does not include specific ethical gui...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What is the core controller of the autonomous ...   \n",
       "1   What is considered as utilizing the short-term...   \n",
       "2   What is the purpose of the Chain of Thought (C...   \n",
       "3   What does the Tree of Thoughts (Yao et al. 202...   \n",
       "4   What is the distinct approach called that invo...   \n",
       "..                                                ...   \n",
       "71  Does the text provide any specific examples of...   \n",
       "72  What are the specific programming languages us...   \n",
       "73  Does the text provide any specific examples of...   \n",
       "74  Does the text provide any specific examples of...   \n",
       "75  What are the specific ethical guidelines menti...   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "0                          LLM (large language model)   \n",
       "1   In-context learning, as seen in Prompt Enginee...   \n",
       "2   The purpose of the Chain of Thought (CoT) prom...   \n",
       "3   Tree of Thoughts extends CoT by exploring mult...   \n",
       "4                             LLM+P (Liu et al. 2023)   \n",
       "..                                                ...   \n",
       "71  No, the text does not provide specific example...   \n",
       "72  The text does not specify which programming la...   \n",
       "73  No, the text does not provide specific example...   \n",
       "74  No, the text does not provide specific example...   \n",
       "75  The text does not include specific ethical gui...   \n",
       "\n",
       "                                 ground_truth_context  \n",
       "0   LLM Powered Autonomous Agents\\n    \\nDate: Jun...  \n",
       "1   Memory\\n\\nShort-term memory: I would consider ...  \n",
       "2   Fig. 1. Overview of a LLM-powered autonomous a...  \n",
       "3   Tree of Thoughts (Yao et al. 2023) extends CoT...  \n",
       "4   Another quite distinct approach, LLM+P (Liu et...  \n",
       "..                                                ...  \n",
       "71                                                     \n",
       "72                                                     \n",
       "73                                                     \n",
       "74                                                     \n",
       "75                                                     \n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gen_qa_lst = []\n",
    "\n",
    "for i in range(len(gen_qa)):\n",
    "    qa_dict = gen_qa[i].dict()\n",
    "    qa_dict[\"ground_truth_context\"] = splits[i].page_content\n",
    "    gen_qa_lst.append(qa_dict)\n",
    "    \n",
    "for qa in gen_qa_no_answer:\n",
    "    qa_dict = qa.dict()\n",
    "    qa_dict[\"ground_truth_context\"] = \"\"\n",
    "    gen_qa_lst.append(qa_dict)\n",
    "\n",
    "gen_dataset = pd.DataFrame(gen_qa_lst)\n",
    "gen_dataset.rename(columns={\"answer\": \"ground_truth\"}, inplace=True)\n",
    "gen_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset.to_csv(\"generated_qa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
